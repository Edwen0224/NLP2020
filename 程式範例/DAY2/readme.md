# Topics
```
Text Classification
Text Preprocessing

Word embeddings

RNN Model

Transfer Learning in NLP
```
```
Text Geberation

Char-RNN
```
```
Image Caption
```
# Text Preprocessing
```

```
# Word embeddings(1)
```
one-hot 編碼
```
```
k-hot 編碼
Text Classification初探
```
# Word embeddings(2)
```
一文搞懂word embeddding和keras中的embedding
https://www.jianshu.com/p/b2c33d7e56a5
https://upload-images.jianshu.io/upload_images/4289471-c3f7c5682d3eed4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240

DeepNLP的表示学习·词嵌入来龙去脉·
https://blog.csdn.net/Scotfield_msn/article/details/69075227
```
```
Load text
https://tensorflow.google.cn/tutorials/load_data/text
```
```
Word embeddings
https://tensorflow.google.cn/tutorials/text/word_embeddings
```
```
Text classification with preprocessed text: Movie reviews
https://tensorflow.google.cn/tutorials/keras/text_classification
```
# RNN Model
```
Recurrent Neural Networks (RNN) with Keras
https://tensorflow.google.cn/guide/keras/rnn
```
```
Masking is a way to tell sequence-processing layers that certain timesteps in an input are missing, and thus should be skipped when processing the data.

Padding is a special form of masking were the masked steps are at the start or at the beginning of a sequence. 
Padding comes from the need to encode sequence data into contiguous batches: in order to make all sequences in a batch fit a given standard length, 
it is necessary to pad or truncate some sequences.

https://tensorflow.google.cn/guide/keras/masking_and_padding
```
```
RNN.md
```
# Transfer Learning in NLP
```
Text classification with TensorFlow Hub: Movie reviews
https://www.tensorflow.org/tutorials/keras/text_classification_with_hub
```
