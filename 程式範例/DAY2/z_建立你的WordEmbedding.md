# 建立英文的WordEmbedding
```
https://github.com/MyDearGreatTeacher/NLP2020/blob/master/%E7%A8%8B%E5%BC%8F%E7%AF%84%E4%BE%8B/DAY2/word2vec.ipynb
```
```

```
# 建立中文的WordEmbedding
```
tf.keras 技術者們必讀！深度學習攻略手冊
施威銘研究室 著 旗標科技  2020-02-13
https://www.tenlong.com.tw/products/9789863126034?list_name=srh

第 6 章 預先訓練自己的中文詞向量
6-0 為什麼要預先訓練詞向量
6-1 Word2vec 實作原理
CBOW 連續詞袋模型
Skip-gram 跳字模型
進階 Skip-gram 模型
6-2 建立並訓練 Word2vec 神經網路
6-2-0 建立完整的 Word2vec 架構
6-2-1 取得原始資料 (語料)
維基百科語料
社區問答語料
6-2-2 資料預處理的介紹
解析 JSON 形式：json 套件
簡體轉繁體：opencc 套件
斷詞：Jieba 套件
6-2-3 資料預處理：產生訓練 Word2vec 所需的資料集
Wiki 資料集
```
```


```
